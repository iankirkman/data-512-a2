{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Bias on Wikipedia\n",
    "\n",
    "#### Ian Kirkman, 11/1/2017\n",
    "\n",
    "The goal of this assignment is to explore the ramifications of bias in data. Given the known demographics of english Wikipedia editors (see \"Nationality\" in https://en.wikipedia.org/wiki/Wikipedia:Wikipedians), we anticipate a bias that affects both the scope and quality of english Wikipedia articles for political figures from various countries. We will analyze the coverage and quality metrics of these articles on political figures, and reflect on our findings.\n",
    "\n",
    "*Assignment source: https://wiki.communitydata.cc/HCDS_(Fall_2017)/Assignments#A2:_Bias_in_data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Prerequisites\n",
    "\n",
    "Section 1 covers all the information needed to gather data, import the required libraries, and set user inputs. We start below with libraries and parameters. Gathering data will be broken into precomputed source data ([Section 1.2](#sec1.2)) and data pulled from an API ([Section 1.3](#sec1.3)).\n",
    "\n",
    "### 1.1. Importing Libraries and Setting Parameters\n",
    "\n",
    "This package includes the following libraries for processing and analysis:\n",
    " - `requests`: This is used to pull data from the ORES API.\n",
    " - `json`: This is used to format, save, and load raw data after it's pulled from the source.\n",
    " - `csv`: This is used to load raw data from csv files, and to write processed data to a csv. \n",
    " - `math`: The functions `floor` and `ceil` are used to split the Residual IDs for ORES API calls.\n",
    " - `copy`: The `deepcopy` function is used when processing and analyzing data (Sections 2 and 3). \n",
    " - `operator`: The `itemgetter` function is used when sorting a list of lists (Section 3).\n",
    " - `IPython`: The `display` and `markdown` functions are used to embed the final ranking tables in the notebook.\n",
    " \n",
    "User inputs are also set in this section, and referenced throughout the later processing steps. Inputs are split into categories that correspond to later notebook Sections. \n",
    "\n",
    " - [Section 1.2](#sec1.2) of this notebook covers the raw data CSV files that need to be uploaded to the project directory. The inputs in this section represent the filepaths of those uploaded CSVs.\n",
    "\n",
    " - [Section 1.3](#sec1.3) of this notebook will cover the ORES API calls to collect the raw ORES data. This section of inputs contains the parameters and endpoint used for the ORES API calls, as well as the file location of where to write the raw API call results.\n",
    "\n",
    " - [Section 2](#sec2) of this notebook contains the data processing steps for our project. In that section, we create the dataset of merged data from our 3 sources that is required as assignment output. Below, we enter the file location of where to save the merged data as a CSV file.\n",
    "\n",
    "**Notes and Assumptions:**\n",
    "- For all data paths it is assumed that this notebook lives in the project root directory. All paths should be written from the root.\n",
    "- Project folders are currently split into DATA (all raw data) and OUTPUT (all processing and analysis output).\n",
    "- Raw data files use the naming convention: `source_description_accessdate`.\n",
    "- Raw data must be saved in a json format, and our processed data output must be saved as a CSV. Changing the file extensions in the paths will require updating code in the related sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import math\n",
    "import copy\n",
    "from operator import itemgetter\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "############ BEGIN USER INPUTS ###\n",
    "\n",
    "github_username = 'iankirkman'\n",
    "uw_email = 'ikirkman@uw.edu'\n",
    "headers={'User-Agent' : 'https://github.com/%s'%github_username, 'From' : '%s'%uw_email}\n",
    "\n",
    "# Raw Data Upload Location (from root dir) -- See data source notes in Section 1.2.\n",
    "raw_wp_data_path = 'DATA/wp_page_data_20171101.csv'\n",
    "raw_prb_data_path = 'DATA/prb_population_mid2015_20171101.csv'\n",
    "\n",
    "# ORES Parameters for API calls -- See usage in Section 1.3.\n",
    "ores_endpoint = 'https://ores.wikimedia.org/v3/scores/{project}/?models={model}&revids={revids}'\n",
    "ores_params = {'project' : 'enwiki',\n",
    "               'model'   : 'wp10'}\n",
    "raw_ores_data_path = 'DATA/raw_ores_data_20171101.json'\n",
    "    \n",
    "# Filepaths of Notebook Output (from root dir) - See usage in Section 2.\n",
    "merged_wp_prb_ores_data_path = 'OUTPUT/processed_wp_prb_ores_data.csv' \n",
    "\n",
    "############ END USER INPUTS ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec1.2'></a>\n",
    "### 1.2. Uploading Raw Data from Outside Sources\n",
    "\n",
    "We have three data sources available for this assignment. This section will cover the first two, which are available publicly in CSV format. To use these datasets in our project, we need to pull the CSV files from the online sources and upload them to our data directory.\n",
    "\n",
    "The [Population Reference Bureau (PRB)](http://www.prb.org/DataFinder/Topic/Rankings.aspx?ind=14) website contains a dataset with population counts by country circa mid-2015. A CSV file can be downloaded directly from the link by clicking the Excel icon in the top right side of the page. The CSV file must then be uploaded to the project data directory at the path specified in the inputs above. The only fields we use from this data are `Location` and `Data`, which correspond to 'Country' and 'Population' on our final dataset, respectively.\n",
    "\n",
    "The english Wikipedia page data for political figures by country was provided by Oliver Keyes on [Figshare](https://figshare.com/articles/Untitled_Item/5513449). The CSV file can be downloaded via the download button on the top left, and then uploaded to the project data directory at the path specified in the inputs above. See code and data notes at the link. We will use each field from this dataset, with the following mapping to our final output: 'country' to 'Country', 'page' to 'Article_Name', and 'rev_id' to 'Revision_ID'.\n",
    "\n",
    "**Notes and Assumptions:**\n",
    "- The column order is assumed to be consistent for any data download from these sources. Passive header checking has been added as print statements in Sections 1.3 and 2.\n",
    "- Note that the Wikipedia page data on Figshare has updated a field name from 'last_edit' to 'rev_id'. This change is not currently reflected in the page data documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec1.3'></a>\n",
    "### 1.3. Pulling Raw Data from the ORES API\n",
    "\n",
    "For our third data source, we will be accessing the [Objective Revision Evaluation Service (ORES)](https://www.mediawiki.org/wiki/ORES) API to collect quality score predictions by article (matched on Revision ID). We use the endpoint and parameters specified in Section 1.1 to call the API with multiple Revision IDs smushed together with a vertical line delimiter. The user-input parameters simply specify the project and model for the API call. Version 3 is assumed and hard-coded into the calls below. Revision IDs are added to the parameters after some initial processing steps from the Figshare data.\n",
    "\n",
    "API calls return a nested dictionary. To access the score prediction for a given article (using Rev_ID_001 as an example), we pull: `api_results[ores_params['project']]['scores'][Rev_ID_001][ores_params['model']]['score']['prediction']`. \n",
    "\n",
    "ORES score predictions are classified as (ordered from best to worst):\n",
    "- `FA`: Featured article\n",
    "- `GA`: Good article\n",
    "- `B`: B-class article\n",
    "- `C`: C-class article\n",
    "- `Start`: Start-class article\n",
    "- `Stub`: Stub-class article\n",
    "\n",
    "See the ORES API linked above for further details.\n",
    "\n",
    "We first build a simple get function to return the API call results for a list of Revision IDs. We then batch groups of 50 Revision IDs at a time from the Wikipedia page data, and add the results of each call to our raw ORES data. The combined raw data is exported to a json file in the project data directory, at the path specified in Section 1.1.\n",
    "\n",
    "**Notes and Assumptions:**\n",
    "- Some of the API calls return an error dictionary instead of returning a score prediction. Those error dictionaries are saved in place on the raw data, and dealt with in our processing steps of Section 2.\n",
    "- The pull of Revision IDs from the Figshare data assumes the column ordering is consistent with this download. \n",
    "- See lines marked with `## TEST ##` for passive error checking below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check WP data headers: True\n",
      "Check ores_data for completeness (2):\n",
      "* 1/2: True\n",
      "* 2/2: True\n"
     ]
    }
   ],
   "source": [
    "def get_ores_data(revision_ids):\n",
    "    '''\n",
    "    Returns a json-formatted dictionary of ORES API results for list of \n",
    "    (up to 50) Wikipedia article Revision IDs. \n",
    "    \n",
    "    DEPENDENCIES:\n",
    "     - Requires Wikipedia page data from figshare uploaded to project\n",
    "       data directory specified in Section 1.1.\n",
    "     - Requires ORES endpoint and parameters specified in Sec 1.1.\n",
    "        \n",
    "    INPUTS: \n",
    "     - revision_ids: list of up to 50 revision ids to pull ORES data on\n",
    "    \n",
    "    RETURNS: \n",
    "     - json-formatted nested dictionary \n",
    "     - See ORES API documentation: https://www.mediawiki.org/wiki/ORES\n",
    "    '''\n",
    "    params = {'revids'  : '|'.join(str(x) for x in revision_ids)}\n",
    "    params.update(ores_params)\n",
    "    return requests.get(ores_endpoint.format(**params)).json()\n",
    "\n",
    "# Read uploaded raw CSV of Wikipedia page data\n",
    "# This is needed to collect Revision IDs for ORES API calls\n",
    "# Assumes header row = ['page','country','rev_id'] \n",
    "wp_data = []\n",
    "with open(raw_wp_data_path) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        wp_data.append([row[0],row[1],row[2]])\n",
    "\n",
    "## TEST ##\n",
    "# Check Wikipedia data header row:\n",
    "print('Check WP data headers: %r'%(wp_data[0]==['page','country','rev_id']))\n",
    "     \n",
    "# Consolidate list of Revision IDs for ORES API calls\n",
    "rev_ids = [wp_data[i][2] for i in range(1,len(wp_data))]\n",
    "\n",
    "# Batch groups of 50 Revision IDs for ORES API calls\n",
    "ores_data = get_ores_data(rev_ids[50*math.floor(len(rev_ids)/50):len(rev_ids)+1])\n",
    "for i in range(math.ceil(len(rev_ids)/50)-1):\n",
    "    ores_data[ores_params['project']]['scores']. \\\n",
    "        update(get_ores_data(rev_ids[i*50:(i+1)*50])[ores_params['project']]['scores'])\n",
    "\n",
    "## TEST ##\n",
    "# Check that all rows have been added to ores_data dictionary.\n",
    "print('Check ores_data for completeness (2):')\n",
    "# Check total number of rev_ids in ores_data versus wp_data:\n",
    "print('* 1/2: %r'%(len(ores_data[ores_params['project']]['scores']) == \\\n",
    "                   len(wp_data)-1))# -1 because wp_data has a header row to ignore\n",
    "# Check ores_data contains last row of wp_data:\n",
    "print('* 2/2: %r'%(wp_data[-1][2] in \\\n",
    "                   ores_data[ores_params['project']]['scores']))\n",
    "\n",
    "# Save raw ORES data as json file\n",
    "with open(raw_ores_data_path, 'w') as outfile:\n",
    "    json.dump(ores_data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2'></a>\n",
    "## 2. Processing Data\n",
    "\n",
    "Processing our data requires two merges, which we have broken into two steps below.   \n",
    "\n",
    "### 2.1 Merge Wikipedia and Population Data\n",
    "\n",
    "First we merge the Wikipedia page data with the PRB Population data. Both datasets have a country feature that we can join on. We remove all countries that do not have an exact match in both datasets.\n",
    "\n",
    "Since we create the merged set by iterating over the Wikipedia page data, the countries in the PRB data that are missing are implicitly removed from our result. However, we added some exclusion tracking below so we can reconcile our data. \n",
    "\n",
    "A list of lists is created, called `dsmerge_wp_prb`, with **ordered** headers that correspond to each source value (where WP represents Wikipedia page data and PRB represents PRB population data):\n",
    "\n",
    "| Column | Value Source |\n",
    "| :--- | :--- |\n",
    "| Country\t| WP.country & PRB.Location  |\n",
    "| Article_Name\t| WP.page |\n",
    "| Revision_ID\t| WP.rev_id |\n",
    "| Article_Quality\t| '' |\n",
    "| Population\t| PRB.Data |\n",
    "\n",
    "**Notes and Assumptions:**\n",
    "- Note that the `Article_Quality` field is an empty string placeholder for the merge with ORES data in Section 2.2.\n",
    "- The ordering of the list `dsmerge_wp_prb` is assumed in later processing steps.\n",
    "- Passive checks are added in lines marked by `## TEST ##`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WP Header Check: True\n",
      "PRB Header Check: True\n",
      "Merged Country Check: 187; Match: True\n"
     ]
    }
   ],
   "source": [
    "# Recall the wikipedia page data was read from CSV in Section 1.2.\n",
    "# This can be repeated here if necessary:\n",
    "wp_data = []\n",
    "with open(raw_wp_data_path) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        wp_data.append([row[0],row[1],row[2]]) # Assumes header row = ['page','country','rev_id'] \n",
    "\n",
    "## TEST ##        \n",
    "# Check Wikipedia data header row:\n",
    "print('WP Header Check: %r'%(wp_data[0]==['page','country','rev_id']))\n",
    "        \n",
    "# Read uploaded raw CSV of PRB Population data into dictionary pop_data\n",
    "pop_data = {} # Dict format is: {'country':'population'}\n",
    "hdr = True # Data has header row\n",
    "with open(raw_prb_data_path) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        if len(row)==6: # Ignore title rows, include column headers\n",
    "            ## TEST ##\n",
    "            if hdr: # Check list order in header row\n",
    "                print('PRB Header Check: %r'%(row[0]=='Location' and row[4]=='Data'))\n",
    "                hdr = False\n",
    "            else: # Add data rows (non-header) to dictionary\n",
    "                pop_data[row[0]] = row[4]\n",
    "\n",
    "# Merge PRB population data with Wikipedia data\n",
    "# Note that this leaves an empty column to join Article_Quality from ores_data\n",
    "dsmerge_wp_prb = [['Country','Article_Name','Revision_ID','Article_Quality','Population']]\n",
    "\n",
    "# Tracking exclusions:\n",
    "# By iterating over wp_data below, we are implicitly skipping countries in pop_data \n",
    "    # that are not in wp_data. \n",
    "# Therefore, to keep track of excluded countries in each source, we use the dictionaries:\n",
    "wp_excl,wp_incl = {},{} # add keys as wp countries are skipped\n",
    "pop_excl = copy.deepcopy(pop_data) # remove keys as prb countries are used\n",
    "\n",
    "# Iterate over wp_data to construct merged list:\n",
    "for row in wp_data[1:]: # Skip header row\n",
    "    # We must also skip rows with countries that are not included in pop_data:\n",
    "    if row[1] in pop_data:\n",
    "        dsmerge_wp_prb.append([row[1],row[0],row[2],'',int(pop_data[row[1]].replace(',',''))])\n",
    "        pop_excl.pop(row[1],None)\n",
    "        wp_incl.update({row[1] : 1})\n",
    "    else:\n",
    "        wp_excl.update({row[1] : 1})\n",
    "        \n",
    "# Track totals for data reconciliation:\n",
    "wp_art_incl_ct = len(dsmerge_wp_prb)\n",
    "wp_art_excl_ct = len(wp_data)-len(dsmerge_wp_prb)\n",
    "wp_ctry_incl_ct = len(wp_incl.keys())\n",
    "wp_ctry_excl_ct = len(wp_excl.keys())\n",
    "prb_pop_incl_ct = sum([int(v.replace(',','')) for v in pop_data.values()])  - \\\n",
    "                        sum([int(v.replace(',','')) for v in pop_excl.values()]) \n",
    "prb_pop_excl_ct = sum([int(v.replace(',','')) for v in pop_excl.values()]) \n",
    "prb_ctry_incl_ct = len([k for k in pop_data.keys() if k not in pop_excl.keys()])\n",
    "prb_ctry_excl_ct = len(pop_excl.keys())\n",
    "\n",
    "## TEST ##\n",
    "# Check that number of included countries is the same in both sources\n",
    "print('Merged Country Check: %s; Match: %r'%(format(wp_ctry_incl_ct,','), \\\n",
    "                                             (wp_ctry_incl_ct == prb_ctry_incl_ct)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclusion Reconciliation for WP and PRB Data by Country\n",
    "\n",
    "We can use the tracking values computed above to print some information about the total amount of excluded countries, articles, and people on each of the applicable datasets. This allows us to confirm that we are not excluding a greater propotion than expected, as well as track our data totals throughout all processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WIKIPEDIA DATA RECONCILIATION\n",
      "------------------------------------\n",
      "* Excluded Articles:\n",
      "\tNumber: 1,398\n",
      "\tPercent: 2.96%\n",
      "* Excluded Countries:\n",
      "\tNumber: 32\n",
      "\tPercent: 14.61%\n",
      "* Excluded Country List:\n",
      "\tHondura\n",
      "\tSalvadoran\n",
      "\tSaint Kitts and Nevis\n",
      "\tPalauan\n",
      "\tIvorian\n",
      "\tSaint Vincent and the Grenadines\n",
      "\tRhodesian\n",
      "\tOmani\n",
      "\tNiuean\n",
      "\tEast Timorese\n",
      "\tFaroese\n",
      "\tCape Colony\n",
      "\tSouth Korean\n",
      "\tSamoan\n",
      "\tMontserratian\n",
      "\tPitcairn Islands\n",
      "\tAbkhazia\n",
      "\tCarniolan\n",
      "\tSaint Lucian\n",
      "\tSouth African Republic\n",
      "\tIncan\n",
      "\tChechen\n",
      "\tJersey\n",
      "\tGuernsey\n",
      "\tSouth Ossetian\n",
      "\tCook Island\n",
      "\tTokelauan\n",
      "\tDagestani\n",
      "\tGreenlandic\n",
      "\tOssetian\n",
      "\tSomaliland\n",
      "\tRojava\n",
      "\n",
      "PRB POPULATION DATA RECONCILIATION\n",
      "------------------------------------\n",
      "* Excluded Population:\n",
      "\tRaw Count: 62,366,406\n",
      "\tPercent of Total Pop.: 0.85%\n",
      "* Excluded Countries:\n",
      "\tNumber: 23\n",
      "\tPercent: 10.95%\n",
      "* Excluded Country List:\n",
      "\tBrunei\n",
      "\tChannel Islands\n",
      "\tCote d'Ivoire\n",
      "\tCuracao\n",
      "\tEl Salvador\n",
      "\tFrench Polynesia\n",
      "\tGeorgia\n",
      "\tGuam\n",
      "\tHonduras\n",
      "\tHong Kong, SAR\n",
      "\tMacao, SAR\n",
      "\tMayotte\n",
      "\tNew Caledonia\n",
      "\tOman\n",
      "\tPalau\n",
      "\tPuerto Rico\n",
      "\tReunion\n",
      "\tSamoa\n",
      "\tSt. Kitts-Nevis\n",
      "\tSt. Lucia\n",
      "\tSt. Vincent & the Grenadines\n",
      "\tTimor-Leste\n",
      "\tWestern Sahara\n"
     ]
    }
   ],
   "source": [
    "## DATA RECONCILIATION ##\n",
    "print('WIKIPEDIA DATA RECONCILIATION')\n",
    "print('------------------------------------')\n",
    "print('* Excluded Articles:')\n",
    "print('\\tNumber: %s'%format(wp_art_excl_ct,\",\"))\n",
    "print('\\tPercent: %s'%format((wp_art_excl_ct/(wp_art_excl_ct+wp_art_incl_ct)),\".2%\"))\n",
    "print('* Excluded Countries:')\n",
    "print('\\tNumber: %s'%format(wp_ctry_excl_ct,\",\"))\n",
    "print('\\tPercent: %s'%format((wp_ctry_excl_ct/(wp_ctry_excl_ct+wp_ctry_incl_ct)),\".2%\"))\n",
    "print('* Excluded Country List:')\n",
    "for k in wp_excl.keys():\n",
    "    print('\\t%s'%k)\n",
    "print() # Add whitespace\n",
    "print('PRB POPULATION DATA RECONCILIATION')\n",
    "print('------------------------------------')\n",
    "print('* Excluded Population:')\n",
    "print('\\tRaw Count: %s'%format(prb_pop_excl_ct,\",\"))\n",
    "print('\\tPercent of Total Pop.: %s'%format((prb_pop_excl_ct/(prb_pop_excl_ct+prb_pop_incl_ct)),\".2%\"))\n",
    "print('* Excluded Countries:')\n",
    "print('\\tNumber: %s'%format(prb_ctry_excl_ct,\",\"))\n",
    "print('\\tPercent: %s'%format((prb_ctry_excl_ct/(prb_ctry_excl_ct+prb_ctry_incl_ct)),\".2%\"))\n",
    "print('* Excluded Country List:')\n",
    "for k in pop_excl.keys():\n",
    "    print('\\t%s'%k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Merge ORES Data with the WP/PRB Merged Dataset\n",
    "\n",
    "Now we merge the ORES data with our previously (Section 2.1) merged dataset from the Wikipedia page data and PRB population data. In this step, we will need to remove articles where the Revision ID returned an error dictionary instead of a score predicition in the ORES API call. We will also track our exclusions due to ORES errors to allow for a full data reconciliation.\n",
    "\n",
    "We start with a deep copy of our previously merged data, named `dsmerge_wp_prb_ores`. We match the ORES data on the `Revision_ID` column. If the ORES API returned an error dictionary for that Revision ID, then the row is removed from our list and added to our exclusion tracking. If it returned a score dictionary, then we add the score prediction to the `Article_Quality` column.\n",
    "\n",
    "The final `dsmerge_wp_prb_ores` list of lists dataset has **ordered** headers that correspond to each source value:\n",
    "\n",
    "| Column | Value Source |\n",
    "| :--- | :--- |\n",
    "| Country\t| WP.country & PRB.Location  |\n",
    "| Article_Name\t| WP.page |\n",
    "| Revision_ID\t| WP.rev_id & ORES.revid |\n",
    "| Article_Quality\t| ORES.prediction |\n",
    "| Population\t| PRB.Data |\n",
    "\n",
    "*__This dataset is a requirement of the assignment, and is output to the location specified in the user inputs of Section 1.1.__*\n",
    "\n",
    "**Notes and Assumptions:**\n",
    "- The ordering of the list `dsmerge_wp_prb_ores` is assumed in later processing steps.\n",
    "- Passive checks are added in lines marked by `## TEST ##`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check merged row totals: True\n"
     ]
    }
   ],
   "source": [
    "# If running apart from Section 1, load ores_data from raw json:\n",
    "with open('%s'%(raw_ores_data_path), 'r') as infile:\n",
    "    ores_data = json.load(infile)\n",
    "\n",
    "# We will also need to exclude articles that did not have ORES data.\n",
    "# The list wp_prb_excl will collect any data from the merged wikipedia and prb sources\n",
    "#     that is excluded for not having ORES data.\n",
    "wp_prb_excl = []\n",
    "\n",
    "# Pull raw ORES API data to add quality prediction to merged list:\n",
    "dsmerge_wp_prb_ores = copy.deepcopy(dsmerge_wp_prb)\n",
    "for row in dsmerge_wp_prb_ores[1:]: # skip header row\n",
    "    if 'error' in ores_data[ores_params['project']]['scores'][row[2]][ores_params['model']]:\n",
    "        # No quality data for this article-- remove it from the merged set\n",
    "        wp_prb_excl.append(row)\n",
    "        dsmerge_wp_prb_ores.remove(row)\n",
    "    else:\n",
    "        # Add the quality prediction to the merged data\n",
    "        row[3] = ores_data[ores_params['project']]['scores'][row[2]][ores_params['model']]['score']['prediction']\n",
    "        \n",
    "## TEST ##\n",
    "print('Check merged row totals: %r'%(len(wp_prb_excl)+len(dsmerge_wp_prb_ores)==len(dsmerge_wp_prb)))\n",
    "\n",
    "# Write Merged Dataset to Output CSV file\n",
    "with open(merged_wp_prb_ores_data_path,'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for row in dsmerge_wp_prb_ores:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclusion Reconciliation for ORES data with merged WP/PRB data by Revision ID\n",
    "\n",
    "We can use the tracking values computed above to print some information about the articles excluded by this merge. This allows us to confirm that we are not excluding a greater propotion than expected, as well as track our data totals throughout all processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERGED WP/PRB/ORES DATA RECONCILIATION\n",
      "------------------------------------\n",
      "* Articles from WP/PRB merged set excluded by ORES error:\n",
      "\tOlajide Awosedo (Nigeria, Rev ID: 806811023, Pop: 181,839,400)\n",
      "\tJalal Movaghar (Iran, Rev ID: 807367030, Pop: 78,483,446)\n",
      "\tMohsen Movaghar (Iran, Rev ID: 807367166, Pop: 78,483,446)\n",
      "\tAjay Kannoujiya (India, Rev ID: 807484325, Pop: 1,314,097,616)\n"
     ]
    }
   ],
   "source": [
    "## DATA RECONCILIATION ##\n",
    "print('MERGED WP/PRB/ORES DATA RECONCILIATION')\n",
    "print('------------------------------------')\n",
    "print('* Articles from WP/PRB merged set excluded by ORES error:')\n",
    "for k in wp_prb_excl:\n",
    "    print('\\t%s (%s, Rev ID: %s, Pop: %s)'%(k[1],k[0],k[2],format(k[4],',')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Analysis\n",
    "\n",
    "To analyze the bias in english Wikipedia articles, we compute two metrics for each country in the combined data. To assess coverage of articles in a country, we compute an articles-per-population proportion (reported as a percentage). To assess the quality of articles in a given country, we compute the proportion of articles that are high quality (those that are classified as 'FA' or 'GA', also reported as a percentage).\n",
    "\n",
    "### 3.1 Developing Metrics for Country Ranking\n",
    "\n",
    "We use a `countries` dictionary with country names as key. Each value is a dictionary that includes values for the country's population, total articles, and high-quality articles. After counting all the articles from our final merged dataset into the countries dictionary, we can create a simple table containing each of our two (coverage and quality) metrics for each country row. This table is called `countries_all_pcov_pqual` in the code section below. \n",
    "\n",
    "We can use this `countries_all_pcov_pqual` table of combined metrics along with some simple sorts to obtain the following country-ranking visualizations:\n",
    "- Top Ten Countries by Coverage Proportion (Articles-to-Population)\n",
    "- Bottom Ten Countries by Coverage Proportion (Articles-to-Population)\n",
    "- Top Ten Countries by Proportion of High Quality Articles\n",
    "- Bottom Ten Countries by Proportion of High Quality Articles\n",
    "\n",
    "**Notes and Assumptions:**\n",
    "- Tie-breakers for equal proportions will be based on previous data sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Article counts in dict of dicts with country names as keys\n",
    "# e.g.: {'country': {'population': [population],\n",
    "#                    'tot_articles': [article count],\n",
    "#                    'hq_articles': [high-quality article count]}}\n",
    "countries = {}\n",
    "for row in dsmerge_wp_prb_ores[1:]:\n",
    "    if row[0] in countries:\n",
    "        # add to article counts only\n",
    "        countries[row[0]]['tot_articles'] += 1\n",
    "        if row[3] in ['GA','FA']:\n",
    "            countries[row[0]]['hq_articles'] += 1\n",
    "    else:\n",
    "        # create new dict entry\n",
    "        countries[row[0]] = {'population' : row[4],\n",
    "                             'tot_articles' : 1,\n",
    "                             'hq_articles' : int(row[3] in ['GA','FA'])}\n",
    "        \n",
    "# Create table of all countries with article-per-pop and hq-per-article values\n",
    "countries_all_pcov_pqual = [['country','prop_coverage','prop_quality']] + \\\n",
    "              [[c, \\\n",
    "                countries[c]['tot_articles']/countries[c]['population'], \\\n",
    "                countries[c]['hq_articles']/countries[c]['tot_articles']] \\\n",
    "                for c in countries.keys()]\n",
    "\n",
    "# Pull top/bottom 10 country lists from countries_all_pcov_pqual list\n",
    "# Reference (use of itemgetter): https://stackoverflow.com/questions/10695139/sort-a-list-of-tuples-by-2nd-item-integer-value\n",
    "countries_top10_pcov = [r for r in sorted(countries_all_pcov_pqual[1:],key=itemgetter(1),reverse=True)[:10]]\n",
    "countries_bot10_pcov = [r for r in sorted(countries_all_pcov_pqual[1:],key=itemgetter(1),reverse=False)[:10]]\n",
    "countries_top10_pqual = [r for r in sorted(countries_all_pcov_pqual[1:],key=itemgetter(2),reverse=True)[:10]]\n",
    "countries_bot10_pqual = [r for r in sorted(countries_all_pcov_pqual[1:],key=itemgetter(2),reverse=False)[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Rankings Visualizations\n",
    "\n",
    "We create a simple get function to construct a string that will work with the IPython `markdown` and `display` functions. That function is called for each Rankings display we wish to show. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Top Ten Countries by Coverage Proportion (Articles-to-Population)\n",
       "----\n",
       "|Country|Population|Article-per-Population|High Quality-per-Article\n",
       "|:-------------|-------------:|-----:|-----:|\n",
       "|Nauru|10,860|0.49%|0.0%|\n",
       "|Tuvalu|11,800|0.47%|5.5%|\n",
       "|San Marino|33,000|0.25%|0.0%|\n",
       "|Monaco|38,088|0.11%|0.0%|\n",
       "|Liechtenstein|37,570|0.08%|0.0%|\n",
       "|Marshall Islands|55,000|0.07%|0.0%|\n",
       "|Iceland|330,828|0.06%|1.0%|\n",
       "|Tonga|103,300|0.06%|0.0%|\n",
       "|Andorra|78,000|0.04%|0.0%|\n",
       "|Federated States of Micronesia|103,000|0.04%|0.0%|\n",
       "\n",
       "\n",
       "\n",
       "Bottom Ten Countries by Coverage Proportion (Articles-to-Population)\n",
       "----\n",
       "|Country|Population|Article-per-Population|High Quality-per-Article\n",
       "|:-------------|-------------:|-----:|-----:|\n",
       "|India|1,314,097,616|0.00%|1.3%|\n",
       "|China|1,371,920,000|0.00%|3.1%|\n",
       "|Indonesia|255,741,973|0.00%|3.7%|\n",
       "|Uzbekistan|31,290,791|0.00%|10.3%|\n",
       "|Ethiopia|98,148,000|0.00%|2.9%|\n",
       "|Korea, North|24,983,000|0.00%|23.1%|\n",
       "|Zambia|15,473,900|0.00%|0.0%|\n",
       "|Thailand|65,121,250|0.00%|2.7%|\n",
       "|Congo, Dem. Rep. of|73,340,200|0.00%|5.6%|\n",
       "|Bangladesh|160,411,000|0.00%|0.9%|\n",
       "\n",
       "\n",
       "\n",
       "Top Ten Countries by Proportion of High Quality Articles\n",
       "----\n",
       "|Country|Population|Article-per-Population|High Quality-per-Article\n",
       "|:-------------|-------------:|-----:|-----:|\n",
       "|Korea, North|24,983,000|0.00%|23.1%|\n",
       "|Saudi Arabia|31,565,109|0.00%|11.8%|\n",
       "|Uzbekistan|31,290,791|0.00%|10.3%|\n",
       "|Central African Republic|5,551,900|0.00%|10.3%|\n",
       "|Romania|19,838,662|0.00%|9.8%|\n",
       "|Guinea-Bissau|1,788,000|0.00%|9.5%|\n",
       "|Bhutan|757,000|0.00%|9.1%|\n",
       "|Vietnam|91,714,080|0.00%|8.4%|\n",
       "|Dominica|68,000|0.02%|8.3%|\n",
       "|Mauritania|3,641,288|0.00%|7.7%|\n",
       "\n",
       "\n",
       "\n",
       "Bottom Ten Countries by Proportion of High Quality Articles\n",
       "----\n",
       "|Country|Population|Article-per-Population|High Quality-per-Article\n",
       "|:-------------|-------------:|-----:|-----:|\n",
       "|Zambia|15,473,900|0.00%|0.0%|\n",
       "|Solomon Islands|641,900|0.02%|0.0%|\n",
       "|Nepal|28,039,000|0.00%|0.0%|\n",
       "|Costa Rica|4,832,000|0.00%|0.0%|\n",
       "|Moldova|4,109,000|0.01%|0.0%|\n",
       "|Finland|5,476,031|0.01%|0.0%|\n",
       "|Switzerland|8,292,851|0.00%|0.0%|\n",
       "|Belgium|11,211,064|0.00%|0.0%|\n",
       "|San Marino|33,000|0.25%|0.0%|\n",
       "|Turkmenistan|5,373,000|0.00%|0.0%|\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_embedstr_ranktab(title,rank_table):\n",
    "    '''\n",
    "    Creates an embedding string for a country-ranking table via \n",
    "    the IPython markdown function.\n",
    "    \n",
    "    INPUT:\n",
    "        - title: the name of the table to display\n",
    "        - rank_table: the rankings table to display\n",
    "        \n",
    "    RETURNS:\n",
    "        - the string used by IPython display(markdown()) function \n",
    "          to embed the country-rankings table\n",
    "    '''\n",
    "    embstr = '%s\\n----\\n'%title + \\\n",
    "             '|Country|Population|Article-per-Population|High Quality-per-Article\\n' + \\\n",
    "             '|:-------------|-------------:|-----:|-----:|\\n'\n",
    "    for c in rank_table:\n",
    "        embstr += '|%s|%s|%s|%s|\\n'%(c[0],format(countries[c[0]]['population'],','),format(c[1],'.2%'),format(c[2],'.1%'))\n",
    "    return embstr + '\\n\\n\\n'\n",
    "\n",
    "# Display Country Ranking tables in markdown.\n",
    "# Reference: https://stackoverflow.com/questions/36288670/jupyter-notebook-output-in-markdown\n",
    "mkdwn_str = get_embedstr_ranktab('Top Ten Countries by Coverage Proportion (Articles-to-Population)', \\\n",
    "                                 countries_top10_pcov) + \\\n",
    "            get_embedstr_ranktab('Bottom Ten Countries by Coverage Proportion (Articles-to-Population)', \\\n",
    "                                 countries_bot10_pcov) + \\\n",
    "            get_embedstr_ranktab('Top Ten Countries by Proportion of High Quality Articles', \\\n",
    "                                 countries_top10_pqual) + \\\n",
    "            get_embedstr_ranktab('Bottom Ten Countries by Proportion of High Quality Articles', \\\n",
    "                                 countries_bot10_pqual)\n",
    "            \n",
    "display(Markdown(mkdwn_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reflections\n",
    "\n",
    "By completing this assignment, I learned more about data processing and reconciliation steps through experience. While I have some career experience reconciling health data for actuarial analysis, it is new to return to Python and work within an open science framework. I found that I am not very comfortable with the ORES API documentation, and I'm glad we were provided an example to work with. \n",
    "\n",
    "#### The English Wikipedia Bias\n",
    "\n",
    "The remainder of my analysis assumes the nationality-bias in english Wikipedia reported on the [Wikipedia Editors Page](https://en.wikipedia.org/wiki/Wikipedia:Wikipedians). The source states that the nationality of english Wikipedia editors is described as 20% United States. India is indicated as the only non-European/North American country in the top 10 of english Wikipedia editors. \n",
    "\n",
    "#### Coverage Findings\n",
    "\n",
    "The countries with the top 10 coverage proportions (article-per-population) all represent countries with very small populations, so I do not feel like this is a strong metric for representation. However, the table uncovered an interesting surprise that Tuvalu has both a high coverage proportion (.47%) and a high quality proportion (5.5%). While the low population makes the coverage proportion volatile/unreliable, the high quality proportion is an interesting outlier that could further be explored. \n",
    "\n",
    "Similarly, the massive populations in the bottom 10 coverage rankings obscure the result. The large population of India could explain the reason it was included in the top 10 number of editors to english Wikipedia. Since we are considering the coverage of articles proportional to the population size of a country, I wonder if it might also have been beneficial to consider the nationality-bias of editors normalized to their nation's proportion of the world population as well. This seems like it may create a stronger link than using raw editor counts for each country.  \n",
    "\n",
    "#### Quality Findings\n",
    "\n",
    "I expected the bias in Wikipedia editors to lead to a more self-reflexive content, e.g.: highest proportion of quality articles to be the United States. However, with South Korea and Saudi Arabia at the top of the list, it seems that the higher quality articles may be focused on areas of high interest in the majority of editor's home-country. This theory assumes the ORES algorithm is accurately grading high quality articles, and there is not some other component of interest inflating their scores. The bottom 10 of the proportion of high quality articles did not surprise me, as the list contains countries that do not reflect the nationalities or countries in conflict/of interest to the predominant nationalities of the majority of english Wikipedia editors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
